### Machine Learning Engineering Intern, Advertising Algorithm Team  
**Xiaohongshu (Rednotes), Shanghai, China**  
**Mar 2025 – Jun 2025**  
Tech: TensorFlow, Git, Docker, Scikit-learn, Pandas, AWS, Spark, Kafka, Matplotlib  
- Designed a production-grade Calibration Tower to correct severe prediction bias (initial PAOA 0.41) in a delayed modeling framework. Benchmarking + Platt Scaling delivered +1.21% eCPM, -1.83% CPA, and 68% improvement in stability (PAOA std 0.25 → 0.08) in A/B tests.  
- Engineered a Temporal Interest Network (TIN) with dual temporal-positional encoding and target-aware attention for a large-scale recommender (20M+ DAU), achieving +2.13% eCPM lift and -1.65% CPA reduction.

---

### Research Assistant – Fairness in Medical & Healthcare Input for LLMs  
**University of Notre Dame, IN, USA**  
**Mar 2024 – Sep 2024** · Mentor: Prof. Yiyu Shi  
Tech: Python, PyTorch, Transformers, Huggingface, Librosa, Torchaudio, Pandas  
- Identified fairness issues in ASR + LLM systems for individuals with speech-related disorders; evaluated optimal model pairings for constrained edge environments.  
- Conducted large-scale benchmarking (15 ASR, 23 LLM models), uncovering systemic performance bias; applied causal tracing to localize bias origin within the ASR-LLM pipeline.

---

### Research Assistant – Event & Frame Fusion for Occlusion Robustness  
**Wuhan University, Wuhan, China**  
**Jun 2023 – Mar 2025** · Mentor: Prof. Lei Yu  
Project: All-in-Focus Seeing Through Occlusion with Event and Frame  
Tech: Python, PyTorch, NumPy, ROS, OpenCV, Torchvision  
- Architected an end-to-end PyTorch pipeline fusing sparse real-time event data with dense image frames to recover occluded scene content.  
- Developed a hybrid model with Swin-Transformer, dynamic convolutions, and multi-task learning; composite loss balanced accuracy and perceptual quality.  
- Built and augmented a custom dataset (1,700+ samples), surpassing SOTA with 90% reduction in depth prediction error and +5 dB PSNR gain.

---

### Versatile Event Transformer for Human Behavior Analysis  
**Independent Project / Collaboration**  
Tech: Python, PyTorch, NumPy, OpenCV, Torchvision, Parquet, Matplotlib  
- Designed a multi-task spatiotemporal Transformer performing joint classification and signal regression with a hybrid KL-Divergence + Pearson correlation loss.  
- Created voxel-guided attention via a Temporal Attention Module combining local 3D CNN patterns with sparse voxel-informed global context.  
- Implemented a preprocessing pipeline (>4,000 simulated event-stream samples) converting sparse asynchronous events into dual spatiotemporal representations for efficient training.
